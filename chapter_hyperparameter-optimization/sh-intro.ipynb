{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9d0ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext d2lbook.tab\n",
    "tab.interact_select([\"pytorch\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e056e19c",
   "metadata": {},
   "source": [
    "# Multi-Fidelity Hyperparameter Optimization\n",
    ":label:`sec_mf_hpo`\n",
    "\n",
    "Training neural networks can be expensive even on moderate size datasets.\n",
    "Depending on the configuration space (:numref:`sec_intro_config_spaces`),\n",
    "hyperparameter optimization requires tens to hundreds of function evaluations\n",
    "to find a well-performing hyperparameter configuration. As we have seen in\n",
    ":numref:`sec_rs_async`, we can significantly speed up the overall wall-clock\n",
    "time of HPO by exploiting parallel resources, but this does not reduce the total\n",
    "amount of compute required.\n",
    "\n",
    "In this section, we will show how the evaluation of hyperparameter configurations\n",
    "can be sped up. Methods such as random search allocate the same amount of\n",
    "resources (e.g., number of epochs, training data points) to each hyperparameter\n",
    "evaluation. :numref:`img_samples_lc` depicts learning curves of a set of neural\n",
    "networks trained with different hyperparameter configurations. After a few epochs we are\n",
    "already able to visually distinguish between well-performing and suboptimal\n",
    "configurations. However, the learning curves are noisy, and we might still require\n",
    "the full amount of 100 epochs to identify the best performing one.\n",
    "\n",
    "![Learning curves of random hyperparameter configurations](../img/samples_lc.svg)\n",
    ":label:`img_samples_lc`\n",
    "\n",
    "Multi-fidelity hyperparameter optimization allocates more resources\n",
    "to promising configurations and stop evaluations of poorly performing ones early.\n",
    "This speeds up the optimization process, since we can try a larger number of\n",
    "configurations for the same total amount of resources.\n",
    "\n",
    "More formally, we expand our definition in :numref:`sec_definition_hpo`,\n",
    "such that our objective function $f(\\mathbf{x}, r)$ gets an additional input\n",
    "$r \\in [r_{\\mathrm{min}}, r_{max}]$, specifying the amount of resources that we are\n",
    "willing to spend for the evaluation of configuration $\\mathbf{x}$. We assume that\n",
    "the error $f(\\mathbf{x}, r)$ decreases with $r$, whereas the computational\n",
    "cost $c(\\mathbf{x}, r)$ increases. Typically, $r$ represents the number of\n",
    "epochs for training the neural network, but it could also be the training\n",
    "subset size or the number of cross-validation folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66eac493",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tab pytorch\n",
    "from d2l import torch as d2l\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from collections import defaultdict\n",
    "d2l.set_figsize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0200057",
   "metadata": {},
   "source": [
    "## Successive Halving\n",
    ":label:`sec_mf_hpo_sh`\n",
    "\n",
    "One of the simplest ways to adapt random search to the multi-fidelity setting is\n",
    "*successive halving* :cite:`jamieson-aistats16,karnin-icml13`. The basic\n",
    "idea is to start with $N$ configurations, for example randomly sampled from the\n",
    "configuration space, and to train each of them for $r_{\\mathrm{min}}$ epochs only. We\n",
    "then discard a fraction of the worst performing trials and train the remaining\n",
    "ones for longer. Iterating this process, fewer trials run for longer, until at\n",
    "least one trial reaches $r_{max}$ epochs.\n",
    "\n",
    "More formally, consider a minimum budget $r_{\\mathrm{min}}$ (for example 1 epoch), a maximum\n",
    "budget $r_{max}$, for example `max_epochs` in our previous example, and a halving\n",
    "constant $\\eta\\in\\{2, 3, \\dots\\}$. For simplicity, assume that\n",
    "$r_{max} = r_{\\mathrm{min}} \\eta^K$, with $K \\in \\mathbb{I}$ . The number of initial\n",
    "configurations is then $N = \\eta^K$. Let us define the set of rungs\n",
    "$\\mathcal{R} = \\{ r_{\\mathrm{min}}, r_{\\mathrm{min}}\\eta, r_{\\mathrm{min}}\\eta^2, \\dots, r_{max} \\}$.\n",
    "\n",
    "One round of successive halving proceeds as follows. We start with running $N$\n",
    "trials until the first rung $r_{\\mathrm{min}}$. Sorting the validation errors, we keep\n",
    "the top $1 / \\eta$ fraction (which amounts to $\\eta^{K-1}$ configurations) and\n",
    "discard all the rest. The surviving trials are trained for the next rung\n",
    "($r_{\\mathrm{min}}\\eta$ epochs), and the process is repeated. At each rung, a\n",
    "$1 / \\eta$ fraction of trials survives and their training continues with a\n",
    "$\\eta$ times larger budget. With this particular choice of $N$, only a single\n",
    "trial will be trained to the full budget $r_{max}$. Once such a round of\n",
    "successive halving is done, we start the next one with a new set of initial\n",
    "configurations, iterating until the total budget is spent.\n",
    "\n",
    "![Learning curves of random hyperparameter configurations.](../img/sh.svg)\n",
    "\n",
    "We subclass the `HPOScheduler` base class from :numref:`sec_api_hpo` in order to\n",
    "implement successive halving, allowing for a generic `HPOSearcher` object to\n",
    "sample configurations (which, in our example below, will be a `RandomSearcher`).\n",
    "Additionally, the user has to pass the minimum resource $r_{\\mathrm{min}}$, the maximum\n",
    "resource $r_{max}$ and $\\eta$ as input. Inside our scheduler, we maintain a\n",
    "queue of configurations that still need to be evaluated for the current rung\n",
    "$r_i$. We update the queue every time we jump to the next rung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15951b9f",
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "2"
    }
   },
   "outputs": [],
   "source": [
    "class SuccessiveHalvingScheduler(d2l.HPOScheduler):  #@save\n",
    "    def __init__(self, searcher, eta, r_min, r_max, prefact=1):\n",
    "        self.save_hyperparameters()\n",
    "        # Compute K, which is later used to determine the number of configurations\n",
    "        self.K = int(np.log(r_max / r_min) / np.log(eta))\n",
    "        # Define the rungs\n",
    "        self.rung_levels = [r_min * eta ** k for k in range(self.K + 1)]\n",
    "        if r_max not in self.rung_levels:\n",
    "            # The final rung should be r_max\n",
    "            self.rung_levels.append(r_max)\n",
    "            self.K += 1\n",
    "        # Bookkeeping\n",
    "        self.observed_error_at_rungs = defaultdict(list)\n",
    "        self.all_observed_error_at_rungs = defaultdict(list)\n",
    "        # Our processing queue\n",
    "        self.queue = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64462844",
   "metadata": {},
   "source": [
    "In the beginning our queue is empty, and we fill it with\n",
    "$n = \\textrm{prefact} \\cdot \\eta^{K}$ configurations, which are first evaluated on\n",
    "the smallest rung $r_{\\mathrm{min}}$. Here, $\\textrm{prefact}$ allows us to reuse our\n",
    "code in a different context. For the purpose of this section, we fix\n",
    "$\\textrm{prefact} = 1$. Every time resources become available and the `HPOTuner`\n",
    "object queries the `suggest` function, we return an element from the queue. Once\n",
    "we finish one round of successive halving, which means that we evaluated all\n",
    "surviving configurations on the highest resource level $r_{max}$ and our queue\n",
    "is empty, we start the entire process again with a new, randomly sampled set\n",
    "of configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68dd17de",
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "12"
    }
   },
   "outputs": [],
   "source": [
    "%%tab pytorch\n",
    "@d2l.add_to_class(SuccessiveHalvingScheduler)  #@save\n",
    "def suggest(self):\n",
    "    if len(self.queue) == 0:\n",
    "        # Start a new round of successive halving\n",
    "        # Number of configurations for the first rung:\n",
    "        n0 = int(self.prefact * self.eta ** self.K)\n",
    "        for _ in range(n0):\n",
    "            config = self.searcher.sample_configuration()\n",
    "            config[\"max_epochs\"] = self.r_min  # Set r = r_min\n",
    "            self.queue.append(config)\n",
    "    # Return an element from the queue\n",
    "    return self.queue.pop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dced972",
   "metadata": {},
   "source": [
    "When we collected a new data point, we first update the searcher module.\n",
    "Afterwards we check if we already collect all data points on the current rung.\n",
    "If so, we sort all configurations and push the top $\\frac{1}{\\eta}$\n",
    "configurations into the queue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7420a718",
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "4"
    }
   },
   "outputs": [],
   "source": [
    "%%tab pytorch\n",
    "@d2l.add_to_class(SuccessiveHalvingScheduler)  #@save\n",
    "def update(self, config: dict, error: float, info=None):\n",
    "    ri = int(config[\"max_epochs\"])  # Rung r_i\n",
    "    # Update our searcher, e.g if we use Bayesian optimization later\n",
    "    self.searcher.update(config, error, additional_info=info)\n",
    "    self.all_observed_error_at_rungs[ri].append((config, error))\n",
    "    if ri < self.r_max:\n",
    "        # Bookkeeping\n",
    "        self.observed_error_at_rungs[ri].append((config, error))\n",
    "        # Determine how many configurations should be evaluated on this rung\n",
    "        ki = self.K - self.rung_levels.index(ri)\n",
    "        ni = int(self.prefact * self.eta ** ki)\n",
    "        # If we observed all configuration on this rung r_i, we estimate the\n",
    "        # top 1 / eta configuration, add them to queue and promote them for\n",
    "        # the next rung r_{i+1}\n",
    "        if len(self.observed_error_at_rungs[ri]) >= ni:\n",
    "            kiplus1 = ki - 1\n",
    "            niplus1 = int(self.prefact * self.eta ** kiplus1)\n",
    "            best_performing_configurations = self.get_top_n_configurations(\n",
    "                rung_level=ri, n=niplus1\n",
    "            )\n",
    "            riplus1 = self.rung_levels[self.K - kiplus1]  # r_{i+1}\n",
    "            # Queue may not be empty: insert new entries at the beginning\n",
    "            self.queue = [\n",
    "                dict(config, max_epochs=riplus1)\n",
    "                for config in best_performing_configurations\n",
    "            ] + self.queue\n",
    "            self.observed_error_at_rungs[ri] = []  # Reset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0c5851",
   "metadata": {},
   "source": [
    "Configurations are sorted based on their observed performance on the current\n",
    "rung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dce3f72",
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "4"
    }
   },
   "outputs": [],
   "source": [
    "%%tab pytorch\n",
    "\n",
    "@d2l.add_to_class(SuccessiveHalvingScheduler)  #@save\n",
    "def get_top_n_configurations(self, rung_level, n):\n",
    "    rung = self.observed_error_at_rungs[rung_level]\n",
    "    if not rung:\n",
    "        return []\n",
    "    sorted_rung = sorted(rung, key=lambda x: x[1])\n",
    "    return [x[0] for x in sorted_rung[:n]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a97c16",
   "metadata": {},
   "source": [
    "Let us see how successive halving is doing on our neural network example. We\n",
    "will use $r_{\\mathrm{min}} = 2$, $\\eta = 2$, $r_{max} = 10$, so that rung levels are\n",
    "$2, 4, 8, 10$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b405451a",
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "5"
    }
   },
   "outputs": [],
   "source": [
    "min_number_of_epochs = 2\n",
    "max_number_of_epochs = 10\n",
    "eta = 2\n",
    "num_gpus=1\n",
    "\n",
    "config_space = {\n",
    "    \"learning_rate\": stats.loguniform(1e-2, 1),\n",
    "    \"batch_size\": stats.randint(32, 256),\n",
    "}\n",
    "initial_config = {\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"batch_size\": 128,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a0afdb",
   "metadata": {},
   "source": [
    "We just replace the scheduler with our new `SuccessiveHalvingScheduler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48ae3c0b",
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "14"
    }
   },
   "outputs": [],
   "source": [
    "searcher = d2l.RandomSearcher(config_space, initial_config=initial_config)\n",
    "scheduler = SuccessiveHalvingScheduler(\n",
    "    searcher=searcher,\n",
    "    eta=eta,\n",
    "    r_min=min_number_of_epochs,\n",
    "    r_max=max_number_of_epochs,\n",
    ")\n",
    "tuner = d2l.HPOTuner(\n",
    "    scheduler=scheduler,\n",
    "    objective=d2l.hpo_objective_lenet,\n",
    ")\n",
    "tuner.run(number_of_trials=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f469359",
   "metadata": {},
   "source": [
    "We can visualize the learning curves of all configurations that we evaluated.\n",
    "Most of the configurations are stopped early and only the better performing\n",
    "configurations survive until $r_{max}$. Compare this to vanilla random search,\n",
    "which would allocate $r_{max}$ to every configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd8db5af",
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "19"
    }
   },
   "outputs": [],
   "source": [
    "for rung_index, rung in scheduler.all_observed_error_at_rungs.items():\n",
    "    errors = [xi[1] for xi in rung]\n",
    "    d2l.plt.scatter([rung_index] * len(errors), errors)\n",
    "d2l.plt.xlim(min_number_of_epochs - 0.5, max_number_of_epochs + 0.5)\n",
    "d2l.plt.xticks(\n",
    "    np.arange(min_number_of_epochs, max_number_of_epochs + 1),\n",
    "    np.arange(min_number_of_epochs, max_number_of_epochs + 1)\n",
    ")\n",
    "d2l.plt.ylabel(\"validation error\")\n",
    "d2l.plt.xlabel(\"epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7dea301",
   "metadata": {},
   "source": [
    "Finally, note some slight complexity in our implementation of\n",
    "`SuccessiveHalvingScheduler`. Say that a worker is free to run a job, and\n",
    "`suggest` is called when the current rung has almost been completely filled, but\n",
    "another worker is still busy with an evaluation. Since we lack the metric value\n",
    "from this worker, we cannot determine the top $1 / \\eta$ fraction to open up\n",
    "the next rung. On the other hand, we want to assign a job to our free worker,\n",
    "so it does not remain idle. Our solution is to start a new round of successive\n",
    "halving and assign our worker to the first trial there. However, once a rung is\n",
    "completed in `update`, we make sure to insert new configurations at the\n",
    "beginning of the queue, so they take precedence over configurations from the\n",
    "next round.\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this section, we introduced the concept of multi-fidelity hyperparameter\n",
    "optimization, where we assume to have access to cheap-to-evaluate approximations\n",
    "of the objective function, such as validation error after a certain number of\n",
    "epochs of training as proxy to validation error after the full number of epochs.\n",
    "Multi-fidelity hyperparameter optimization allows to reduce the overall\n",
    "computation of the HPO instead of just reducing the wall-clock time.\n",
    "\n",
    "We implemented and evaluated successive halving, a simple yet efficient\n",
    "multi-fidelity HPO algorithm.\n",
    "\n",
    "\n",
    ":begin_tab:`pytorch`\n",
    "[Discussions](https://discuss.d2l.ai/t/12094)\n",
    ":end_tab:"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
