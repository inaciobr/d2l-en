{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08024584",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext d2lbook.tab\n",
    "tab.interact_select(['mxnet', 'pytorch', 'tensorflow', 'jax'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8706e941",
   "metadata": {},
   "source": [
    "# Custom Layers\n",
    "\n",
    "One factor behind deep learning's success\n",
    "is the availability of a wide range of layers\n",
    "that can be composed in creative ways\n",
    "to design architectures suitable\n",
    "for a wide variety of tasks.\n",
    "For instance, researchers have invented layers\n",
    "specifically for handling images, text,\n",
    "looping over sequential data,\n",
    "and\n",
    "performing dynamic programming.\n",
    "Sooner or later, you will need\n",
    "a layer that does not exist yet in the deep learning framework.\n",
    "In these cases, you must build a custom layer.\n",
    "In this section, we show you how."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e073aa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tab mxnet\n",
    "from d2l import mxnet as d2l\n",
    "from mxnet import np, npx\n",
    "from mxnet.gluon import nn\n",
    "npx.set_np()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a1cd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tab pytorch\n",
    "from d2l import torch as d2l\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cee83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tab tensorflow\n",
    "from d2l import tensorflow as d2l\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86d94ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tab jax\n",
    "from d2l import jax as d2l\n",
    "from flax import linen as nn\n",
    "import jax\n",
    "from jax import numpy as jnp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd53285b",
   "metadata": {},
   "source": [
    "## (**Layers without Parameters**)\n",
    "\n",
    "To start, we construct a custom layer\n",
    "that does not have any parameters of its own.\n",
    "This should look familiar if you recall our\n",
    "introduction to modules in :numref:`sec_model_construction`.\n",
    "The following `CenteredLayer` class simply\n",
    "subtracts the mean from its input.\n",
    "To build it, we simply need to inherit\n",
    "from the base layer class and implement the forward propagation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667849e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tab mxnet\n",
    "class CenteredLayer(nn.Block):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return X - X.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f206e2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tab pytorch\n",
    "class CenteredLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, X):\n",
    "        return X - X.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675f326c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tab tensorflow\n",
    "class CenteredLayer(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def call(self, X):\n",
    "        return X - tf.reduce_mean(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb63063f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tab jax\n",
    "class CenteredLayer(nn.Module):\n",
    "    def __call__(self, X):\n",
    "        return X - X.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872bf530",
   "metadata": {},
   "source": [
    "Let's verify that our layer works as intended by feeding some data through it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7485aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tab all\n",
    "layer = CenteredLayer()\n",
    "layer(d2l.tensor([1.0, 2, 3, 4, 5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe7d326",
   "metadata": {},
   "source": [
    "We can now [**incorporate our layer as a component\n",
    "in constructing more complex models.**]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838ca5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tab mxnet\n",
    "net = nn.Sequential()\n",
    "net.add(nn.Dense(128), CenteredLayer())\n",
    "net.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196fbf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tab pytorch\n",
    "net = nn.Sequential(nn.LazyLinear(128), CenteredLayer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cdf288",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tab tensorflow\n",
    "net = tf.keras.Sequential([tf.keras.layers.Dense(128), CenteredLayer()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d6a38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tab jax\n",
    "net = nn.Sequential([nn.Dense(128), CenteredLayer()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4ea45e",
   "metadata": {},
   "source": [
    "As an extra sanity check, we can send random data\n",
    "through the network and check that the mean is in fact 0.\n",
    "Because we are dealing with floating point numbers,\n",
    "we may still see a very small nonzero number\n",
    "due to quantization.\n",
    "\n",
    ":begin_tab:`jax`\n",
    "Here we utilize the `init_with_output` method which returns both the output of\n",
    "the network as well as the parameters. In this case we only focus on the\n",
    "output.\n",
    ":end_tab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f17119",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tab pytorch, mxnet\n",
    "Y = net(d2l.rand(4, 8))\n",
    "Y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98d8bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tab tensorflow\n",
    "Y = net(tf.random.uniform((4, 8)))\n",
    "tf.reduce_mean(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f637d75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tab jax\n",
    "Y, _ = net.init_with_output(d2l.get_key(), jax.random.uniform(d2l.get_key(),\n",
    "                                                              (4, 8)))\n",
    "Y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0fee62",
   "metadata": {},
   "source": [
    "## [**Layers with Parameters**]\n",
    "\n",
    "Now that we know how to define simple layers,\n",
    "let's move on to defining layers with parameters\n",
    "that can be adjusted through training.\n",
    "We can use built-in functions to create parameters, which\n",
    "provide some basic housekeeping functionality.\n",
    "In particular, they govern access, initialization,\n",
    "sharing, saving, and loading model parameters.\n",
    "This way, among other benefits, we will not need to write\n",
    "custom serialization routines for every custom layer.\n",
    "\n",
    "Now let's implement our own version of the  fully connected layer.\n",
    "Recall that this layer requires two parameters,\n",
    "one to represent the weight and the other for the bias.\n",
    "In this implementation, we bake in the ReLU activation as a default.\n",
    "This layer requires two input arguments: `in_units` and `units`, which\n",
    "denote the number of inputs and outputs, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43138286",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tab mxnet\n",
    "class MyDense(nn.Block):\n",
    "    def __init__(self, units, in_units, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.weight = self.params.get('weight', shape=(in_units, units))\n",
    "        self.bias = self.params.get('bias', shape=(units,))\n",
    "\n",
    "    def forward(self, x):\n",
    "        linear = np.dot(x, self.weight.data(ctx=x.ctx)) + self.bias.data(\n",
    "            ctx=x.ctx)\n",
    "        return npx.relu(linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431d562a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tab pytorch\n",
    "class MyLinear(nn.Module):\n",
    "    def __init__(self, in_units, units):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(in_units, units))\n",
    "        self.bias = nn.Parameter(torch.randn(units,))\n",
    "        \n",
    "    def forward(self, X):\n",
    "        linear = torch.matmul(X, self.weight.data) + self.bias.data\n",
    "        return F.relu(linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4140a651",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tab tensorflow\n",
    "class MyDense(tf.keras.Model):\n",
    "    def __init__(self, units):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, X_shape):\n",
    "        self.weight = self.add_weight(name='weight',\n",
    "            shape=[X_shape[-1], self.units],\n",
    "            initializer=tf.random_normal_initializer())\n",
    "        self.bias = self.add_weight(\n",
    "            name='bias', shape=[self.units],\n",
    "            initializer=tf.zeros_initializer())\n",
    "\n",
    "    def call(self, X):\n",
    "        linear = tf.matmul(X, self.weight) + self.bias\n",
    "        return tf.nn.relu(linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d142c1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tab jax\n",
    "class MyDense(nn.Module):\n",
    "    in_units: int\n",
    "    units: int\n",
    "\n",
    "    def setup(self):\n",
    "        self.weight = self.param('weight', nn.initializers.normal(stddev=1),\n",
    "                                 (self.in_units, self.units))\n",
    "        self.bias = self.param('bias', nn.initializers.zeros, self.units)\n",
    "\n",
    "    def __call__(self, X):\n",
    "        linear = jnp.matmul(X, self.weight) + self.bias\n",
    "        return nn.relu(linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebbb577",
   "metadata": {},
   "source": [
    ":begin_tab:`mxnet, tensorflow, jax`\n",
    "Next, we instantiate the `MyDense` class\n",
    "and access its model parameters.\n",
    ":end_tab:\n",
    "\n",
    ":begin_tab:`pytorch`\n",
    "Next, we instantiate the `MyLinear` class\n",
    "and access its model parameters.\n",
    ":end_tab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d6e29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tab mxnet\n",
    "dense = MyDense(units=3, in_units=5)\n",
    "dense.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad76187",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tab pytorch\n",
    "linear = MyLinear(5, 3)\n",
    "linear.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0910564",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tab tensorflow\n",
    "dense = MyDense(3)\n",
    "dense(tf.random.uniform((2, 5)))\n",
    "dense.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38109bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tab jax\n",
    "dense = MyDense(5, 3)\n",
    "params = dense.init(d2l.get_key(), jnp.zeros((3, 5)))\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f42c43b",
   "metadata": {},
   "source": [
    "We can [**directly carry out forward propagation calculations using custom layers.**]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a5e506",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tab mxnet\n",
    "dense.initialize()\n",
    "dense(np.random.uniform(size=(2, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b479bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tab pytorch\n",
    "linear(torch.rand(2, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d05250d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tab tensorflow\n",
    "dense(tf.random.uniform((2, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c84258",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tab jax\n",
    "dense.apply(params, jax.random.uniform(d2l.get_key(),\n",
    "                                       (2, 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb683e61",
   "metadata": {},
   "source": [
    "We can also (**construct models using custom layers.**)\n",
    "Once we have that we can use it just like the built-in fully connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cbf5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tab mxnet\n",
    "net = nn.Sequential()\n",
    "net.add(MyDense(8, in_units=64),\n",
    "        MyDense(1, in_units=8))\n",
    "net.initialize()\n",
    "net(np.random.uniform(size=(2, 64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855700d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tab pytorch\n",
    "net = nn.Sequential(MyLinear(64, 8), MyLinear(8, 1))\n",
    "net(torch.rand(2, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016423ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tab tensorflow\n",
    "net = tf.keras.models.Sequential([MyDense(8), MyDense(1)])\n",
    "net(tf.random.uniform((2, 64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a7b3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tab jax\n",
    "net = nn.Sequential([MyDense(64, 8), MyDense(8, 1)])\n",
    "Y, _ = net.init_with_output(d2l.get_key(), jax.random.uniform(d2l.get_key(),\n",
    "                                                              (2, 64)))\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c8538f",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "We can design custom layers via the basic layer class. This allows us to define flexible new layers that behave differently from any existing layers in the library.\n",
    "Once defined, custom layers can be invoked in arbitrary contexts and architectures.\n",
    "Layers can have local parameters, which can be created through built-in functions.\n",
    "\n",
    "\n",
    "## Exercises\n",
    "\n",
    "1. Design a layer that takes an input and computes a tensor reduction,\n",
    "   i.e., it returns $y_k = \\sum_{i, j} W_{ijk} x_i x_j$.\n",
    "1. Design a layer that returns the leading half of the Fourier coefficients of the data.\n",
    "\n",
    ":begin_tab:`mxnet`\n",
    "[Discussions](https://discuss.d2l.ai/t/58)\n",
    ":end_tab:\n",
    "\n",
    ":begin_tab:`pytorch`\n",
    "[Discussions](https://discuss.d2l.ai/t/59)\n",
    ":end_tab:\n",
    "\n",
    ":begin_tab:`tensorflow`\n",
    "[Discussions](https://discuss.d2l.ai/t/279)\n",
    ":end_tab:\n",
    "\n",
    ":begin_tab:`jax`\n",
    "[Discussions](https://discuss.d2l.ai/t/17993)\n",
    ":end_tab:"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
