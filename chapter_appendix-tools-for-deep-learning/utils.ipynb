{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdd3bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext d2lbook.tab\n",
    "tab.interact_select(['mxnet', 'pytorch', 'tensorflow', 'jax'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f6d214",
   "metadata": {},
   "source": [
    "# Utility Functions and Classes\n",
    ":label:`sec_utils`\n",
    "\n",
    "\n",
    "This section contains the implementations of utility functions and classes used in this book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e38dd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tab mxnet\n",
    "import inspect\n",
    "import collections\n",
    "from d2l import mxnet as d2l\n",
    "from IPython import display\n",
    "from mxnet import autograd, gluon, np, npx\n",
    "from mxnet.gluon import nn\n",
    "import random\n",
    "npx.set_np()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5393febe",
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "1"
    }
   },
   "outputs": [],
   "source": [
    "%%tab pytorch\n",
    "import inspect\n",
    "import collections\n",
    "from d2l import torch as d2l\n",
    "from IPython import display\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf23f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tab tensorflow\n",
    "import inspect\n",
    "from IPython import display\n",
    "import collections\n",
    "from d2l import tensorflow as d2l\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11232bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tab jax\n",
    "import inspect\n",
    "from IPython import display\n",
    "import collections\n",
    "from d2l import jax as d2l\n",
    "import jax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ebaf57",
   "metadata": {},
   "source": [
    "Hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea3d90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tab all\n",
    "@d2l.add_to_class(d2l.HyperParameters)  #@save\n",
    "def save_hyperparameters(self, ignore=[]):\n",
    "    \"\"\"Save function arguments into class attributes.\"\"\"\n",
    "    frame = inspect.currentframe().f_back\n",
    "    _, _, _, local_vars = inspect.getargvalues(frame)\n",
    "    self.hparams = {k:v for k, v in local_vars.items()\n",
    "                    if k not in set(ignore+['self']) and not k.startswith('_')}\n",
    "    for k, v in self.hparams.items():\n",
    "        setattr(self, k, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1993a1fd",
   "metadata": {},
   "source": [
    "Progress bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5c1029d",
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "22"
    }
   },
   "outputs": [],
   "source": [
    "%%tab all\n",
    "@d2l.add_to_class(d2l.ProgressBoard)  #@save\n",
    "def draw(self, x, y, label, every_n=1):\n",
    "    Point = collections.namedtuple('Point', ['x', 'y'])\n",
    "    if not hasattr(self, 'raw_points'):\n",
    "        self.raw_points = collections.OrderedDict()\n",
    "        self.data = collections.OrderedDict()\n",
    "    if label not in self.raw_points:\n",
    "        self.raw_points[label] = []\n",
    "        self.data[label] = []    \n",
    "    points = self.raw_points[label]\n",
    "    line = self.data[label]\n",
    "    points.append(Point(x, y))\n",
    "    if len(points) != every_n:\n",
    "        return    \n",
    "    mean = lambda x: sum(x) / len(x)\n",
    "    line.append(Point(mean([p.x for p in points]), \n",
    "                      mean([p.y for p in points])))\n",
    "    points.clear()\n",
    "    if not self.display: \n",
    "        return\n",
    "    d2l.use_svg_display()\n",
    "    if self.fig is None:\n",
    "        self.fig = d2l.plt.figure(figsize=self.figsize)\n",
    "    plt_lines, labels = [], []\n",
    "    for (k, v), ls, color in zip(self.data.items(), self.ls, self.colors):        \n",
    "        plt_lines.append(d2l.plt.plot([p.x for p in v], [p.y for p in v], \n",
    "                                      linestyle=ls, color=color)[0])\n",
    "        labels.append(k)        \n",
    "    axes = self.axes if self.axes else d2l.plt.gca()\n",
    "    if self.xlim: axes.set_xlim(self.xlim)\n",
    "    if self.ylim: axes.set_ylim(self.ylim)\n",
    "    if not self.xlabel: self.xlabel = self.x    \n",
    "    axes.set_xlabel(self.xlabel)\n",
    "    axes.set_ylabel(self.ylabel)\n",
    "    axes.set_xscale(self.xscale)\n",
    "    axes.set_yscale(self.yscale)\n",
    "    axes.legend(plt_lines, labels)    \n",
    "    display.display(self.fig)\n",
    "    display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbc1955",
   "metadata": {},
   "source": [
    "Add FrozenLake enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b490884e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tab pytorch\n",
    "\n",
    "def frozen_lake(seed): #@save\n",
    "    # See https://www.gymlibrary.dev/environments/toy_text/frozen_lake/ to learn more about this env\n",
    "    # How to process env.P.items is adpated from https://sites.google.com/view/deep-rl-bootcamp/labs\n",
    "    import gym\n",
    "\n",
    "    env = gym.make('FrozenLake-v1', is_slippery=False)\n",
    "    env.seed(seed)\n",
    "    env.action_space.np_random.seed(seed)\n",
    "    env.action_space.seed(seed)\n",
    "    env_info = {}\n",
    "    env_info['desc'] = env.desc  # 2D array specifying what each grid item means\n",
    "    env_info['num_states'] = env.nS  # Number of observations/states or obs/state dim\n",
    "    env_info['num_actions'] = env.nA  # Number of actions or action dim\n",
    "    # Define indices for (transition probability, nextstate, reward, done) tuple\n",
    "    env_info['trans_prob_idx'] = 0  # Index of transition probability entry\n",
    "    env_info['nextstate_idx'] = 1  # Index of next state entry\n",
    "    env_info['reward_idx'] = 2  # Index of reward entry\n",
    "    env_info['done_idx'] = 3  # Index of done entry\n",
    "    env_info['mdp'] = {}\n",
    "    env_info['env'] = env\n",
    "\n",
    "    for (s, others) in env.P.items():\n",
    "        # others(s) = {a0: [ (p(s'|s,a0), s', reward, done),...], a1:[...], ...}\n",
    "\n",
    "        for (a, pxrds) in others.items():\n",
    "            # pxrds is [(p1,next1,r1,d1),(p2,next2,r2,d2),..].\n",
    "            # e.g. [(0.3, 0, 0, False), (0.3, 0, 0, False), (0.3, 4, 1, False)]\n",
    "            env_info['mdp'][(s,a)] = pxrds\n",
    "\n",
    "    return env_info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1172712f",
   "metadata": {},
   "source": [
    "Create enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb69713",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tab pytorch\n",
    "\n",
    "def make_env(name ='', seed=0): #@save\n",
    "    # Input parameters:\n",
    "    # name: specifies a gym environment.\n",
    "    # For Value iteration, only FrozenLake-v1 is supported.\n",
    "    if name == 'FrozenLake-v1':\n",
    "        return frozen_lake(seed)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"%s env is not supported in this Notebook\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c99db67",
   "metadata": {},
   "source": [
    "Show value function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399b6c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tab pytorch\n",
    "\n",
    "def show_value_function_progress(env_desc, V, pi): #@save\n",
    "    # This function visualizes how value and policy changes over time.\n",
    "    # V: [num_iters, num_states]\n",
    "    # pi: [num_iters, num_states]\n",
    "    # How to visualize value function is adapted (but changed) from: https://sites.google.com/view/deep-rl-bootcamp/labs\n",
    "\n",
    "    num_iters = V.shape[0]\n",
    "    fig, ax  = plt.subplots(figsize=(15, 15))\n",
    "\n",
    "    for k in range(V.shape[0]):\n",
    "        plt.subplot(4, 4, k + 1)\n",
    "        plt.imshow(V[k].reshape(4,4), cmap=\"bone\")\n",
    "        ax = plt.gca()\n",
    "        ax.set_xticks(np.arange(0, 5)-.5, minor=True)\n",
    "        ax.set_yticks(np.arange(0, 5)-.5, minor=True)\n",
    "        ax.grid(which=\"minor\", color=\"w\", linestyle='-', linewidth=3)\n",
    "        ax.tick_params(which=\"minor\", bottom=False, left=False)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "        # LEFT action: 0, DOWN action: 1\n",
    "        # RIGHT action: 2, UP action: 3\n",
    "        action2dxdy = {0:(-.25, 0),1: (0, .25),\n",
    "                       2:(0.25, 0),3: (-.25, 0)}\n",
    "\n",
    "        for y in range(4):\n",
    "            for x in range(4):\n",
    "                action = pi[k].reshape(4,4)[y, x]\n",
    "                dx, dy = action2dxdy[action]\n",
    "\n",
    "                if env_desc[y,x].decode() == 'H':\n",
    "                    ax.text(x, y, str(env_desc[y,x].decode()),\n",
    "                       ha=\"center\", va=\"center\", color=\"y\",\n",
    "                         size=20, fontweight='bold')\n",
    "\n",
    "                elif env_desc[y,x].decode() == 'G':\n",
    "                    ax.text(x, y, str(env_desc[y,x].decode()),\n",
    "                       ha=\"center\", va=\"center\", color=\"w\",\n",
    "                         size=20, fontweight='bold')\n",
    "\n",
    "                else:\n",
    "                    ax.text(x, y, str(env_desc[y,x].decode()),\n",
    "                       ha=\"center\", va=\"center\", color=\"g\",\n",
    "                         size=15, fontweight='bold')\n",
    "\n",
    "                # No arrow for cells with G and H labels\n",
    "                if env_desc[y,x].decode() != 'G' and env_desc[y,x].decode() != 'H':\n",
    "                    ax.arrow(x, y, dx, dy, color='r', head_width=0.2, head_length=0.15)\n",
    "\n",
    "        ax.set_title(\"Step = \"  + str(k + 1), fontsize=20)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4629a4",
   "metadata": {},
   "source": [
    "Show Q function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ac7d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tab pytorch\n",
    "\n",
    "def show_Q_function_progress(env_desc, V_all, pi_all): #@save\n",
    "    # This function visualizes how value and policy changes over time.\n",
    "    # V: [num_iters, num_states]\n",
    "    # pi: [num_iters, num_states]\n",
    "\n",
    "    # We want to only shows few values\n",
    "    num_iters_all = V_all.shape[0]\n",
    "    num_iters = num_iters_all // 10\n",
    "\n",
    "    vis_indx = np.arange(0, num_iters_all, num_iters).tolist()\n",
    "    vis_indx.append(num_iters_all - 1)\n",
    "    V = np.zeros((len(vis_indx), V_all.shape[1]))\n",
    "    pi = np.zeros((len(vis_indx), V_all.shape[1]))\n",
    "\n",
    "    for c, i in enumerate(vis_indx):\n",
    "        V[c]  = V_all[i]\n",
    "        pi[c] = pi_all[i]\n",
    "\n",
    "    num_iters = V.shape[0]\n",
    "    fig, ax = plt.subplots(figsize=(15, 15))\n",
    "\n",
    "    for k in range(V.shape[0]):\n",
    "        plt.subplot(4, 4, k + 1)\n",
    "        plt.imshow(V[k].reshape(4,4), cmap=\"bone\")\n",
    "        ax = plt.gca()\n",
    "        ax.set_xticks(np.arange(0, 5)-.5, minor=True)\n",
    "        ax.set_yticks(np.arange(0, 5)-.5, minor=True)\n",
    "        ax.grid(which=\"minor\", color=\"w\", linestyle='-', linewidth=3)\n",
    "        ax.tick_params(which=\"minor\", bottom=False, left=False)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "        # LEFT action: 0, DOWN action: 1\n",
    "        # RIGHT action: 2, UP action: 3\n",
    "        action2dxdy = {0:(-.25, 0),1:(0, .25),\n",
    "                       2:(0.25, 0),3:(-.25, 0)}\n",
    "\n",
    "        for y in range(4):\n",
    "            for x in range(4):\n",
    "                action = pi[k].reshape(4,4)[y, x]\n",
    "                dx, dy = action2dxdy[action]\n",
    "\n",
    "                if env_desc[y,x].decode() == 'H':\n",
    "                    ax.text(x, y, str(env_desc[y,x].decode()),\n",
    "                       ha=\"center\", va=\"center\", color=\"y\",\n",
    "                         size=20, fontweight='bold')\n",
    "\n",
    "                elif env_desc[y,x].decode() == 'G':\n",
    "                    ax.text(x, y, str(env_desc[y,x].decode()),\n",
    "                       ha=\"center\", va=\"center\", color=\"w\",\n",
    "                         size=20, fontweight='bold')\n",
    "\n",
    "                else:\n",
    "                    ax.text(x, y, str(env_desc[y,x].decode()),\n",
    "                       ha=\"center\", va=\"center\", color=\"g\",\n",
    "                         size=15, fontweight='bold')\n",
    "\n",
    "                # No arrow for cells with G and H labels\n",
    "                if env_desc[y,x].decode() != 'G' and env_desc[y,x].decode() != 'H':\n",
    "                    ax.arrow(x, y, dx, dy, color='r', head_width=0.2, head_length=0.15)\n",
    "\n",
    "        ax.set_title(\"Step = \"  + str(vis_indx[k] + 1), fontsize=20)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c88fb20",
   "metadata": {},
   "source": [
    "Trainer\n",
    "\n",
    "A bunch of functions that will be deprecated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e4568a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tab mxnet\n",
    "def load_array(data_arrays, batch_size, is_train=True):  #@save\n",
    "    \"\"\"Construct a Gluon data iterator.\"\"\"\n",
    "    dataset = gluon.data.ArrayDataset(*data_arrays)\n",
    "    return gluon.data.DataLoader(dataset, batch_size, shuffle=is_train)\n",
    "\n",
    "def synthetic_data(w, b, num_examples):  #@save\n",
    "    \"\"\"Generate y = Xw + b + noise.\"\"\"\n",
    "    X = d2l.normal(0, 1, (num_examples, len(w)))\n",
    "    y = d2l.matmul(X, w) + b\n",
    "    y += d2l.normal(0, 0.01, y.shape)\n",
    "    return X, d2l.reshape(y, (-1, 1))\n",
    "\n",
    "def sgd(params, lr, batch_size):  #@save\n",
    "    \"\"\"Minibatch stochastic gradient descent.\"\"\"\n",
    "    for param in params:\n",
    "        param[:] = param - lr * param.grad / batch_size\n",
    "\n",
    "def get_dataloader_workers():  #@save\n",
    "    \"\"\"Use 4 processes to read the data except for Windows.\"\"\"\n",
    "    return 0 if sys.platform.startswith('win') else 4\n",
    "\n",
    "def load_data_fashion_mnist(batch_size, resize=None):  #@save\n",
    "    \"\"\"Download the Fashion-MNIST dataset and then load it into memory.\"\"\"\n",
    "    dataset = gluon.data.vision\n",
    "    trans = [dataset.transforms.ToTensor()]\n",
    "    if resize:\n",
    "        trans.insert(0, dataset.transforms.Resize(resize))\n",
    "    trans = dataset.transforms.Compose(trans)\n",
    "    mnist_train = dataset.FashionMNIST(train=True).transform_first(trans)\n",
    "    mnist_test = dataset.FashionMNIST(train=False).transform_first(trans)\n",
    "    return (gluon.data.DataLoader(mnist_train, batch_size, shuffle=True,\n",
    "                                  num_workers=get_dataloader_workers()),\n",
    "            gluon.data.DataLoader(mnist_test, batch_size, shuffle=False,\n",
    "                                  num_workers=get_dataloader_workers()))\n",
    "\n",
    "def evaluate_accuracy_gpu(net, data_iter, device=None):  #@save\n",
    "    \"\"\"Compute the accuracy for a model on a dataset using a GPU.\"\"\"\n",
    "    if not device:  # Query the first device where the first parameter is on\n",
    "        device = list(net.collect_params().values())[0].list_ctx()[0]\n",
    "    # No. of correct predictions, no. of predictions\n",
    "    metric = d2l.Accumulator(2)\n",
    "    for X, y in data_iter:\n",
    "        X, y = X.as_in_ctx(device), y.as_in_ctx(device)\n",
    "        metric.add(d2l.accuracy(net(X), y), d2l.size(y))\n",
    "    return metric[0] / metric[1]\n",
    "\n",
    "#@save\n",
    "def train_ch6(net, train_iter, test_iter, num_epochs, lr, device):\n",
    "    \"\"\"Train a model with a GPU (defined in Chapter 6).\"\"\"\n",
    "    net.initialize(force_reinit=True, ctx=device, init=init.Xavier())\n",
    "    loss = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "    trainer = gluon.Trainer(net.collect_params(),\n",
    "                            'sgd', {'learning_rate': lr})\n",
    "    animator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs],\n",
    "                            legend=['train loss', 'train acc', 'test acc'])\n",
    "    timer, num_batches = d2l.Timer(), len(train_iter)\n",
    "    for epoch in range(num_epochs):\n",
    "        # Sum of training loss, sum of training accuracy, no. of examples\n",
    "        metric = d2l.Accumulator(3)\n",
    "        for i, (X, y) in enumerate(train_iter):\n",
    "            timer.start()\n",
    "            # Here is the major difference from `d2l.train_epoch_ch3`\n",
    "            X, y = X.as_in_ctx(device), y.as_in_ctx(device)\n",
    "            with autograd.record():\n",
    "                y_hat = net(X)\n",
    "                l = loss(y_hat, y)\n",
    "            l.backward()\n",
    "            trainer.step(X.shape[0])\n",
    "            metric.add(l.sum(), d2l.accuracy(y_hat, y), X.shape[0])\n",
    "            timer.stop()\n",
    "            train_l = metric[0] / metric[2]\n",
    "            train_acc = metric[1] / metric[2]\n",
    "            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n",
    "                animator.add(epoch + (i + 1) / num_batches,\n",
    "                             (train_l, train_acc, None))\n",
    "        test_acc = evaluate_accuracy_gpu(net, test_iter)\n",
    "        animator.add(epoch + 1, (None, None, test_acc))\n",
    "    print(f'loss {train_l:.3f}, train acc {train_acc:.3f}, '\n",
    "          f'test acc {test_acc:.3f}')\n",
    "    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec '\n",
    "          f'on {str(device)}')\n",
    "    \n",
    "def grad_clipping(net, theta):  #@save\n",
    "    \"\"\"Clip the gradient.\"\"\"\n",
    "    if isinstance(net, gluon.Block):\n",
    "        params = [p.data() for p in net.collect_params().values()]\n",
    "    else:\n",
    "        params = net.params\n",
    "    norm = math.sqrt(sum((p.grad ** 2).sum() for p in params))\n",
    "    if norm > theta:\n",
    "        for param in params:\n",
    "            param.grad[:] *= theta / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf1d4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tab pytorch\n",
    "\n",
    "def load_array(data_arrays, batch_size, is_train=True):  #@save\n",
    "    \"\"\"Construct a PyTorch data iterator.\"\"\"\n",
    "    dataset = torch.utils.data.TensorDataset(*data_arrays)\n",
    "    return torch.utils.data.DataLoader(dataset, batch_size, shuffle=is_train)\n",
    "\n",
    "def synthetic_data(w, b, num_examples):  #@save\n",
    "    \"\"\"Generate y = Xw + b + noise.\"\"\"\n",
    "    X = d2l.normal(0, 1, (num_examples, len(w)))\n",
    "    y = d2l.matmul(X, w) + b\n",
    "    y += d2l.normal(0, 0.01, y.shape)\n",
    "    return X, d2l.reshape(y, (-1, 1))\n",
    "\n",
    "def sgd(params, lr, batch_size): #@save\n",
    "    \"\"\"Minibatch stochastic gradient descent.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        for param in params:\n",
    "            param -= lr * param.grad / batch_size\n",
    "            param.grad.zero_()\n",
    "\n",
    "def get_dataloader_workers():  #@save\n",
    "    \"\"\"Use 4 processes to read the data.\"\"\"\n",
    "    return 4\n",
    "\n",
    "def load_data_fashion_mnist(batch_size, resize=None):  #@save\n",
    "    \"\"\"Download the Fashion-MNIST dataset and then load it into memory.\"\"\"\n",
    "    trans = [transforms.ToTensor()]\n",
    "    if resize:\n",
    "        trans.insert(0, transforms.Resize(resize))\n",
    "    trans = transforms.Compose(trans)\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(\n",
    "        root=\"../data\", train=True, transform=trans, download=True)\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(\n",
    "        root=\"../data\", train=False, transform=trans, download=True)\n",
    "    return (torch.utils.data.DataLoader(mnist_train, batch_size, shuffle=True,\n",
    "                                        num_workers=get_dataloader_workers()),\n",
    "            torch.utils.data.DataLoader(mnist_test, batch_size, shuffle=False,\n",
    "                                        num_workers=get_dataloader_workers()))\n",
    "\n",
    "def evaluate_accuracy_gpu(net, data_iter, device=None): #@save\n",
    "    \"\"\"Compute the accuracy for a model on a dataset using a GPU.\"\"\"\n",
    "    if isinstance(net, nn.Module):\n",
    "        net.eval()  # Set the model to evaluation mode\n",
    "        if not device:\n",
    "            device = next(iter(net.parameters())).device\n",
    "    # No. of correct predictions, no. of predictions\n",
    "    metric = d2l.Accumulator(2)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            if isinstance(X, list):\n",
    "                # Required for BERT Fine-tuning (to be covered later)\n",
    "                X = [x.to(device) for x in X]\n",
    "            else:\n",
    "                X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            metric.add(d2l.accuracy(net(X), y), d2l.size(y))\n",
    "    return metric[0] / metric[1]\n",
    "\n",
    "\n",
    "#@save\n",
    "def train_ch6(net, train_iter, test_iter, num_epochs, lr, device):\n",
    "    \"\"\"Train a model with a GPU (defined in Chapter 6).\"\"\"\n",
    "    def init_weights(m):\n",
    "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "    net.apply(init_weights)\n",
    "    print('training on', device)\n",
    "    net.to(device)\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    animator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs],\n",
    "                            legend=['train loss', 'train acc', 'test acc'])\n",
    "    timer, num_batches = d2l.Timer(), len(train_iter)\n",
    "    for epoch in range(num_epochs):\n",
    "        # Sum of training loss, sum of training accuracy, no. of examples\n",
    "        metric = d2l.Accumulator(3)\n",
    "        net.train()\n",
    "        for i, (X, y) in enumerate(train_iter):\n",
    "            timer.start()\n",
    "            optimizer.zero_grad()\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                metric.add(l * X.shape[0], d2l.accuracy(y_hat, y), X.shape[0])\n",
    "            timer.stop()\n",
    "            train_l = metric[0] / metric[2]\n",
    "            train_acc = metric[1] / metric[2]\n",
    "            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n",
    "                animator.add(epoch + (i + 1) / num_batches,\n",
    "                             (train_l, train_acc, None))\n",
    "        test_acc = evaluate_accuracy_gpu(net, test_iter)\n",
    "        animator.add(epoch + 1, (None, None, test_acc))\n",
    "    print(f'loss {train_l:.3f}, train acc {train_acc:.3f}, '\n",
    "          f'test acc {test_acc:.3f}')\n",
    "    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec '\n",
    "          f'on {str(device)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef6a07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tab tensorflow\n",
    "\n",
    "def load_array(data_arrays, batch_size, is_train=True):  #@save\n",
    "    \"\"\"Construct a TensorFlow data iterator.\"\"\"\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(data_arrays)\n",
    "    if is_train:\n",
    "        dataset = dataset.shuffle(buffer_size=1000)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset\n",
    "\n",
    "def synthetic_data(w, b, num_examples):  #@save\n",
    "    \"\"\"Generate y = Xw + b + noise.\"\"\"\n",
    "    X = tf.zeros((num_examples, w.shape[0]))\n",
    "    X += tf.random.normal(shape=X.shape)\n",
    "    y = tf.matmul(X, tf.reshape(w, (-1, 1))) + b\n",
    "    y += tf.random.normal(shape=y.shape, stddev=0.01)\n",
    "    y = tf.reshape(y, (-1, 1))\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def sgd(params, grads, lr, batch_size):  #@save\n",
    "    \"\"\"Minibatch stochastic gradient descent.\"\"\"\n",
    "    for param, grad in zip(params, grads):\n",
    "        param.assign_sub(lr * grad / batch_size)\n",
    "\n",
    "def load_data_fashion_mnist(batch_size, resize=None):   #@save\n",
    "    \"\"\"Download the Fashion-MNIST dataset and then load it into memory.\"\"\"\n",
    "    mnist_train, mnist_test = tf.keras.datasets.fashion_mnist.load_data()\n",
    "    # Divide all numbers by 255 so that all pixel values are between\n",
    "    # 0 and 1, add a batch dimension at the last. And cast label to int32\n",
    "    process = lambda X, y: (tf.expand_dims(X, axis=3) / 255,\n",
    "                            tf.cast(y, dtype='int32'))\n",
    "    resize_fn = lambda X, y: (\n",
    "        tf.image.resize_with_pad(X, resize, resize) if resize else X, y)\n",
    "    return (\n",
    "        tf.data.Dataset.from_tensor_slices(process(*mnist_train)).batch(\n",
    "            batch_size).shuffle(len(mnist_train[0])).map(resize_fn),\n",
    "        tf.data.Dataset.from_tensor_slices(process(*mnist_test)).batch(\n",
    "            batch_size).map(resize_fn))\n",
    "\n",
    "class TrainCallback(tf.keras.callbacks.Callback):  #@save\n",
    "    \"\"\"A callback to visiualize the training progress.\"\"\"\n",
    "    def __init__(self, net, train_iter, test_iter, num_epochs, device_name):\n",
    "        self.timer = d2l.Timer()\n",
    "        self.animator = d2l.Animator(\n",
    "            xlabel='epoch', xlim=[1, num_epochs], legend=[\n",
    "                'train loss', 'train acc', 'test acc'])\n",
    "        self.net = net\n",
    "        self.train_iter = train_iter\n",
    "        self.test_iter = test_iter\n",
    "        self.num_epochs = num_epochs\n",
    "        self.device_name = device_name\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.timer.start()\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        self.timer.stop()\n",
    "        test_acc = self.net.evaluate(\n",
    "            self.test_iter, verbose=0, return_dict=True)['accuracy']\n",
    "        metrics = (logs['loss'], logs['accuracy'], test_acc)\n",
    "        self.animator.add(epoch + 1, metrics)\n",
    "        if epoch == self.num_epochs - 1:\n",
    "            batch_size = next(iter(self.train_iter))[0].shape[0]\n",
    "            num_examples = batch_size * tf.data.experimental.cardinality(\n",
    "                self.train_iter).numpy()\n",
    "            print(f'loss {metrics[0]:.3f}, train acc {metrics[1]:.3f}, '\n",
    "                  f'test acc {metrics[2]:.3f}')\n",
    "            print(f'{num_examples / self.timer.avg():.1f} examples/sec on '\n",
    "                  f'{str(self.device_name)}')\n",
    "\n",
    "#@save\n",
    "def train_ch6(net_fn, train_iter, test_iter, num_epochs, lr, device):\n",
    "    \"\"\"Train a model with a GPU (defined in Chapter 6).\"\"\"\n",
    "    device_name = device._device_name\n",
    "    strategy = tf.distribute.OneDeviceStrategy(device_name)\n",
    "    with strategy.scope():\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=lr)\n",
    "        loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "        net = net_fn()\n",
    "        net.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "    callback = TrainCallback(net, train_iter, test_iter, num_epochs,\n",
    "                             device_name)\n",
    "    net.fit(train_iter, epochs=num_epochs, verbose=0, callbacks=[callback])\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fed8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tab mxnet, tensorflow\n",
    "def evaluate_accuracy(net, data_iter):  #@save\n",
    "    \"\"\"Compute the accuracy for a model on a dataset.\"\"\"\n",
    "    metric = Accumulator(2)  # No. of correct predictions, no. of predictions\n",
    "    for X, y in data_iter:\n",
    "        metric.add(accuracy(net(X), y), d2l.size(y))\n",
    "    return metric[0] / metric[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bc31b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tab all\n",
    "def show_images(imgs, num_rows, num_cols, titles=None, scale=1.5):  #@save\n",
    "    \"\"\"Plot a list of images.\"\"\"\n",
    "    figsize = (num_cols * scale, num_rows * scale)\n",
    "    _, axes = d2l.plt.subplots(num_rows, num_cols, figsize=figsize)\n",
    "    axes = axes.flatten()\n",
    "    for i, (ax, img) in enumerate(zip(axes, imgs)):\n",
    "        try:\n",
    "            img = d2l.numpy(img)\n",
    "        except:\n",
    "            pass\n",
    "        ax.imshow(img)\n",
    "        ax.axes.get_xaxis().set_visible(False)\n",
    "        ax.axes.get_yaxis().set_visible(False)\n",
    "        if titles:\n",
    "            ax.set_title(titles[i])\n",
    "    return axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cbe1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tab pytorch, mxnet, tensorflow\n",
    "\n",
    "def linreg(X, w, b):  #@save\n",
    "    \"\"\"The linear regression model.\"\"\"\n",
    "    return d2l.matmul(X, w) + b\n",
    "\n",
    "def squared_loss(y_hat, y):  #@save\n",
    "    \"\"\"Squared loss.\"\"\"\n",
    "    return (y_hat - d2l.reshape(y, y_hat.shape)) ** 2 / 2\n",
    "\n",
    "def get_fashion_mnist_labels(labels):  #@save\n",
    "    \"\"\"Return text labels for the Fashion-MNIST dataset.\"\"\"\n",
    "    text_labels = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat',\n",
    "                   'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
    "    return [text_labels[int(i)] for i in labels]\n",
    "\n",
    "#@tab pytorch, mxnet, tensorflow\n",
    "class Animator:  #@save\n",
    "    \"\"\"For plotting data in animation.\"\"\"\n",
    "    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,\n",
    "                 ylim=None, xscale='linear', yscale='linear',\n",
    "                 fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1,\n",
    "                 figsize=(3.5, 2.5)):\n",
    "        # Incrementally plot multiple lines\n",
    "        if legend is None:\n",
    "            legend = []\n",
    "        d2l.use_svg_display()\n",
    "        self.fig, self.axes = d2l.plt.subplots(nrows, ncols, figsize=figsize)\n",
    "        if nrows * ncols == 1:\n",
    "            self.axes = [self.axes, ]\n",
    "        # Use a lambda function to capture arguments\n",
    "        self.config_axes = lambda: d2l.set_axes(\n",
    "            self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n",
    "        self.X, self.Y, self.fmts = None, None, fmts\n",
    "\n",
    "    def add(self, x, y):\n",
    "        # Add multiple data points into the figure\n",
    "        if not hasattr(y, \"__len__\"):\n",
    "            y = [y]\n",
    "        n = len(y)\n",
    "        if not hasattr(x, \"__len__\"):\n",
    "            x = [x] * n\n",
    "        if not self.X:\n",
    "            self.X = [[] for _ in range(n)]\n",
    "        if not self.Y:\n",
    "            self.Y = [[] for _ in range(n)]\n",
    "        for i, (a, b) in enumerate(zip(x, y)):\n",
    "            if a is not None and b is not None:\n",
    "                self.X[i].append(a)\n",
    "                self.Y[i].append(b)\n",
    "        self.axes[0].cla()\n",
    "        for x, y, fmt in zip(self.X, self.Y, self.fmts):\n",
    "            self.axes[0].plot(x, y, fmt)\n",
    "        self.config_axes()\n",
    "        display.display(self.fig)\n",
    "        display.clear_output(wait=True)\n",
    "\n",
    "#@tab pytorch, mxnet, tensorflow\n",
    "class Accumulator:  #@save\n",
    "    \"\"\"For accumulating sums over `n` variables.\"\"\"\n",
    "    def __init__(self, n):\n",
    "        self.data = [0.0] * n\n",
    "\n",
    "    def add(self, *args):\n",
    "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
    "\n",
    "    def reset(self):\n",
    "        self.data = [0.0] * len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "\n",
    "#@tab pytorch, mxnet, tensorflow\n",
    "def accuracy(y_hat, y):  #@save\n",
    "    \"\"\"Compute the number of correct predictions.\"\"\"\n",
    "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
    "        y_hat = d2l.argmax(y_hat, axis=1)\n",
    "    cmp = d2l.astype(y_hat, y.dtype) == y\n",
    "    return float(d2l.reduce_sum(d2l.astype(cmp, y.dtype)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f80b46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tab all\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "import tarfile\n",
    "import hashlib\n",
    "\n",
    "def download(url, folder='../data', sha1_hash=None):  #@save\n",
    "    \"\"\"Download a file to folder and return the local filepath.\"\"\"\n",
    "    if not url.startswith('http'):\n",
    "        # For back compatability\n",
    "        url, sha1_hash = DATA_HUB[url]\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    fname = os.path.join(folder, url.split('/')[-1])\n",
    "    # Check if hit cache\n",
    "    if os.path.exists(fname) and sha1_hash:\n",
    "        sha1 = hashlib.sha1()\n",
    "        with open(fname, 'rb') as f:\n",
    "            while True:\n",
    "                data = f.read(1048576)\n",
    "                if not data:\n",
    "                    break\n",
    "                sha1.update(data)\n",
    "        if sha1.hexdigest() == sha1_hash:\n",
    "            return fname\n",
    "    # Download\n",
    "    print(f'Downloading {fname} from {url}...')\n",
    "    r = requests.get(url, stream=True, verify=True)\n",
    "    with open(fname, 'wb') as f:\n",
    "        f.write(r.content)\n",
    "    return fname\n",
    "\n",
    "def extract(filename, folder=None):  #@save\n",
    "    \"\"\"Extract a zip/tar file into folder.\"\"\"\n",
    "    base_dir = os.path.dirname(filename)\n",
    "    _, ext = os.path.splitext(filename)\n",
    "    assert ext in ('.zip', '.tar', '.gz'), 'Only support zip/tar files.'\n",
    "    if ext == '.zip':\n",
    "        fp = zipfile.ZipFile(filename, 'r')\n",
    "    else:\n",
    "        fp = tarfile.open(filename, 'r')\n",
    "    if folder is None:\n",
    "        folder = base_dir\n",
    "    fp.extractall(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3ede63",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tab pytorch, mxnet, tensorflow\n",
    "\n",
    "def download_extract(name, folder=None):  #@save\n",
    "    \"\"\"Download and extract a zip/tar file.\"\"\"\n",
    "    fname = download(name)\n",
    "    base_dir = os.path.dirname(fname)\n",
    "    data_dir, ext = os.path.splitext(fname)\n",
    "    if ext == '.zip':\n",
    "        fp = zipfile.ZipFile(fname, 'r')\n",
    "    elif ext in ('.tar', '.gz'):\n",
    "        fp = tarfile.open(fname, 'r')\n",
    "    else:\n",
    "        assert False, 'Only zip/tar files can be extracted.'\n",
    "    fp.extractall(base_dir)\n",
    "    return os.path.join(base_dir, folder) if folder else data_dir\n",
    "\n",
    "\n",
    "def tokenize(lines, token='word'):  #@save\n",
    "    \"\"\"Split text lines into word or character tokens.\"\"\"\n",
    "    assert token in ('word', 'char'), 'Unknown token type: ' + token\n",
    "    return [line.split() if token == 'word' else list(line) for line in lines]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99cc97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tab pytorch\n",
    "\n",
    "def evaluate_loss(net, data_iter, loss):  #@save\n",
    "    \"\"\"Evaluate the loss of a model on the given dataset.\"\"\"\n",
    "    metric = d2l.Accumulator(2)  # Sum of losses, no. of examples\n",
    "    for X, y in data_iter:\n",
    "        out = net(X)\n",
    "        y = d2l.reshape(y, out.shape)\n",
    "        l = loss(out, y)\n",
    "        metric.add(d2l.reduce_sum(l), d2l.size(l))\n",
    "    return metric[0] / metric[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025a7429",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tab mxnet, tensorflow\n",
    "def evaluate_loss(net, data_iter, loss):  #@save\n",
    "    \"\"\"Evaluate the loss of a model on the given dataset.\"\"\"\n",
    "    metric = d2l.Accumulator(2)  # Sum of losses, no. of examples\n",
    "    for X, y in data_iter:\n",
    "        l = loss(net(X), y)\n",
    "        metric.add(d2l.reduce_sum(l), d2l.size(l))\n",
    "    return metric[0] / metric[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e381b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tab pytorch\n",
    "def grad_clipping(net, theta):  #@save\n",
    "    \"\"\"Clip the gradient.\"\"\"\n",
    "    if isinstance(net, nn.Module):\n",
    "        params = [p for p in net.parameters() if p.requires_grad]\n",
    "    else:\n",
    "        params = net.params\n",
    "    norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))\n",
    "    if norm > theta:\n",
    "        for param in params:\n",
    "            param.grad[:] *= theta / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287479f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tab tensorflow\n",
    "def grad_clipping(grads, theta):  #@save\n",
    "    \"\"\"Clip the gradient.\"\"\"\n",
    "    theta = tf.constant(theta, dtype=tf.float32)\n",
    "    new_grad = []\n",
    "    for grad in grads:\n",
    "        if isinstance(grad, tf.IndexedSlices):\n",
    "            new_grad.append(tf.convert_to_tensor(grad))\n",
    "        else:\n",
    "            new_grad.append(grad)\n",
    "    norm = tf.math.sqrt(sum((tf.reduce_sum(grad ** 2)).numpy()\n",
    "                        for grad in new_grad))\n",
    "    norm = tf.cast(norm, tf.float32)\n",
    "    if tf.greater(norm, theta):\n",
    "        for i, grad in enumerate(new_grad):\n",
    "            new_grad[i] = grad * theta / norm\n",
    "    else:\n",
    "        new_grad = new_grad\n",
    "    return new_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd33593",
   "metadata": {},
   "source": [
    "More for the attention chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c5dd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tab pytorch, mxnet, tensorflow\n",
    "#@save\n",
    "d2l.DATA_HUB['fra-eng'] = (d2l.DATA_URL + 'fra-eng.zip',\n",
    "                           '94646ad1522d915e7b0f9296181140edcf86a4f5')\n",
    "\n",
    "#@save\n",
    "def read_data_nmt():\n",
    "    \"\"\"Load the English-French dataset.\"\"\"\n",
    "    data_dir = d2l.download_extract('fra-eng')\n",
    "    with open(os.path.join(data_dir, 'fra.txt'), 'r', encoding='utf-8') as f:\n",
    "        return f.read()\n",
    "\n",
    "#@save\n",
    "def preprocess_nmt(text):\n",
    "    \"\"\"Preprocess the English-French dataset.\"\"\"\n",
    "    def no_space(char, prev_char):\n",
    "        return char in set(',.!?') and prev_char != ' '\n",
    "\n",
    "    # Replace non-breaking space with space, and convert uppercase letters to\n",
    "    # lowercase ones\n",
    "    text = text.replace('\\u202f', ' ').replace('\\xa0', ' ').lower()\n",
    "    # Insert space between words and punctuation marks\n",
    "    out = [' ' + char if i > 0 and no_space(char, text[i - 1]) else char\n",
    "           for i, char in enumerate(text)]\n",
    "    return ''.join(out)\n",
    "\n",
    "#@save\n",
    "def tokenize_nmt(text, num_examples=None):\n",
    "    \"\"\"Tokenize the English-French dataset.\"\"\"\n",
    "    source, target = [], []\n",
    "    for i, line in enumerate(text.split('\\n')):\n",
    "        if num_examples and i > num_examples:\n",
    "            break\n",
    "        parts = line.split('\\t')\n",
    "        if len(parts) == 2:\n",
    "            source.append(parts[0].split(' '))\n",
    "            target.append(parts[1].split(' '))\n",
    "    return source, target\n",
    "\n",
    "    \n",
    "#@save\n",
    "def truncate_pad(line, num_steps, padding_token):\n",
    "    \"\"\"Truncate or pad sequences.\"\"\"\n",
    "    if len(line) > num_steps:\n",
    "        return line[:num_steps]  # Truncate\n",
    "    return line + [padding_token] * (num_steps - len(line))  # Pad\n",
    "\n",
    "\n",
    "#@save\n",
    "def build_array_nmt(lines, vocab, num_steps):\n",
    "    \"\"\"Transform text sequences of machine translation into minibatches.\"\"\"\n",
    "    lines = [vocab[l] for l in lines]\n",
    "    lines = [l + [vocab['<eos>']] for l in lines]\n",
    "    array = d2l.tensor([truncate_pad(\n",
    "        l, num_steps, vocab['<pad>']) for l in lines])\n",
    "    valid_len = d2l.reduce_sum(\n",
    "        d2l.astype(array != vocab['<pad>'], d2l.int32), 1)\n",
    "    return array, valid_len\n",
    "\n",
    "\n",
    "#@save\n",
    "def load_data_nmt(batch_size, num_steps, num_examples=600):\n",
    "    \"\"\"Return the iterator and the vocabularies of the translation dataset.\"\"\"\n",
    "    text = preprocess_nmt(read_data_nmt())\n",
    "    source, target = tokenize_nmt(text, num_examples)\n",
    "    src_vocab = d2l.Vocab(source, min_freq=2,\n",
    "                          reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
    "    tgt_vocab = d2l.Vocab(target, min_freq=2,\n",
    "                          reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
    "    src_array, src_valid_len = build_array_nmt(source, src_vocab, num_steps)\n",
    "    tgt_array, tgt_valid_len = build_array_nmt(target, tgt_vocab, num_steps)\n",
    "    data_arrays = (src_array, src_valid_len, tgt_array, tgt_valid_len)\n",
    "    data_iter = d2l.load_array(data_arrays, batch_size)\n",
    "    return data_iter, src_vocab, tgt_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985b22ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tab mxnet\n",
    "    \n",
    "#@save\n",
    "class MaskedSoftmaxCELoss(gluon.loss.SoftmaxCELoss):\n",
    "    \"\"\"The softmax cross-entropy loss with masks.\"\"\"\n",
    "    # `pred` shape: (`batch_size`, `num_steps`, `vocab_size`)\n",
    "    # `label` shape: (`batch_size`, `num_steps`)\n",
    "    # `valid_len` shape: (`batch_size`,)\n",
    "    def forward(self, pred, label, valid_len):\n",
    "        # `weights` shape: (`batch_size`, `num_steps`, 1)\n",
    "        weights = np.expand_dims(np.ones_like(label), axis=-1)\n",
    "        weights = npx.sequence_mask(weights, valid_len, True, axis=1)\n",
    "        return super(MaskedSoftmaxCELoss, self).forward(pred, label, weights)\n",
    "\n",
    "#@save\n",
    "def train_seq2seq(net, data_iter, lr, num_epochs, tgt_vocab, device):\n",
    "    \"\"\"Train a model for sequence to sequence.\"\"\"\n",
    "    net.initialize(init.Xavier(), force_reinit=True, ctx=device)\n",
    "    trainer = gluon.Trainer(net.collect_params(), 'adam',\n",
    "                            {'learning_rate': lr})\n",
    "    loss = MaskedSoftmaxCELoss()\n",
    "    animator = d2l.Animator(xlabel='epoch', ylabel='loss',\n",
    "                            xlim=[10, num_epochs])\n",
    "    for epoch in range(num_epochs):\n",
    "        timer = d2l.Timer()\n",
    "        metric = d2l.Accumulator(2)  # Sum of training loss, no. of tokens\n",
    "        for batch in data_iter:\n",
    "            X, X_valid_len, Y, Y_valid_len = [\n",
    "                x.as_in_ctx(device) for x in batch]\n",
    "            bos = np.array(\n",
    "                [tgt_vocab['<bos>']] * Y.shape[0], ctx=device).reshape(-1, 1)\n",
    "            dec_input = d2l.concat([bos, Y[:, :-1]], 1)  # Teacher forcing\n",
    "            with autograd.record():\n",
    "                Y_hat, _ = net(X, dec_input, X_valid_len)\n",
    "                l = loss(Y_hat, Y, Y_valid_len)\n",
    "            l.backward()\n",
    "            d2l.grad_clipping(net, 1)\n",
    "            num_tokens = Y_valid_len.sum()\n",
    "            trainer.step(num_tokens)\n",
    "            metric.add(l.sum(), num_tokens)\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            animator.add(epoch + 1, (metric[0] / metric[1],))\n",
    "    print(f'loss {metric[0] / metric[1]:.3f}, {metric[1] / timer.stop():.1f} '\n",
    "          f'tokens/sec on {str(device)}')\n",
    "\n",
    "#@save\n",
    "def predict_seq2seq(net, src_sentence, src_vocab, tgt_vocab, num_steps,\n",
    "                    device, save_attention_weights=False):\n",
    "    \"\"\"Predict for sequence to sequence.\"\"\"\n",
    "    src_tokens = src_vocab[src_sentence.lower().split(' ')] + [\n",
    "        src_vocab['<eos>']]\n",
    "    enc_valid_len = np.array([len(src_tokens)], ctx=device)\n",
    "    src_tokens = d2l.truncate_pad(src_tokens, num_steps, src_vocab['<pad>'])\n",
    "    # Add the batch axis\n",
    "    enc_X = np.expand_dims(np.array(src_tokens, ctx=device), axis=0)\n",
    "    enc_outputs = net.encoder(enc_X, enc_valid_len)\n",
    "    dec_state = net.decoder.init_state(enc_outputs, enc_valid_len)\n",
    "    # Add the batch axis\n",
    "    dec_X = np.expand_dims(np.array([tgt_vocab['<bos>']], ctx=device), axis=0)\n",
    "    output_seq, attention_weight_seq = [], []\n",
    "    for _ in range(num_steps):\n",
    "        Y, dec_state = net.decoder(dec_X, dec_state)\n",
    "        # We use the token with the highest prediction likelihood as input\n",
    "        # of the decoder at the next time step\n",
    "        dec_X = Y.argmax(axis=2)\n",
    "        pred = dec_X.squeeze(axis=0).astype('int32').item()\n",
    "        # Save attention weights (to be covered later)\n",
    "        if save_attention_weights:\n",
    "            attention_weight_seq.append(net.decoder.attention_weights)\n",
    "        # Once the end-of-sequence token is predicted, the generation of the\n",
    "        # output sequence is complete\n",
    "        if pred == tgt_vocab['<eos>']:\n",
    "            break\n",
    "        output_seq.append(pred)\n",
    "    return ' '.join(tgt_vocab.to_tokens(output_seq)), attention_weight_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e7a87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tab pytorch\n",
    "#@save\n",
    "def sequence_mask(X, valid_len, value=0):\n",
    "    \"\"\"Mask irrelevant entries in sequences.\"\"\"\n",
    "    maxlen = X.size(1)\n",
    "    mask = torch.arange((maxlen), dtype=torch.float32,\n",
    "                        device=X.device)[None, :] < valid_len[:, None]\n",
    "    X[~mask] = value\n",
    "    return X\n",
    "\n",
    "    \n",
    "#@save\n",
    "class MaskedSoftmaxCELoss(nn.CrossEntropyLoss):\n",
    "    \"\"\"The softmax cross-entropy loss with masks.\"\"\"\n",
    "    # `pred` shape: (`batch_size`, `num_steps`, `vocab_size`)\n",
    "    # `label` shape: (`batch_size`, `num_steps`)\n",
    "    # `valid_len` shape: (`batch_size`,)\n",
    "    def forward(self, pred, label, valid_len):\n",
    "        weights = torch.ones_like(label)\n",
    "        weights = sequence_mask(weights, valid_len)\n",
    "        self.reduction='none'\n",
    "        unweighted_loss = super(MaskedSoftmaxCELoss, self).forward(\n",
    "            pred.permute(0, 2, 1), label)\n",
    "        weighted_loss = (unweighted_loss * weights).mean(dim=1)\n",
    "        return weighted_loss\n",
    "    \n",
    "#@save\n",
    "def train_seq2seq(net, data_iter, lr, num_epochs, tgt_vocab, device):\n",
    "    \"\"\"Train a model for sequence to sequence.\"\"\"\n",
    "    def xavier_init_weights(m):\n",
    "        if type(m) == nn.Linear:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "        if type(m) == nn.GRU:\n",
    "            for param in m._flat_weights_names:\n",
    "                if \"weight\" in param:\n",
    "                    nn.init.xavier_uniform_(m._parameters[param])\n",
    "    net.apply(xavier_init_weights)\n",
    "    net.to(device)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    loss = MaskedSoftmaxCELoss()\n",
    "    net.train()\n",
    "    animator = d2l.Animator(xlabel='epoch', ylabel='loss',\n",
    "                            xlim=[10, num_epochs])\n",
    "    for epoch in range(num_epochs):\n",
    "        timer = d2l.Timer()\n",
    "        metric = d2l.Accumulator(2)  # Sum of training loss, no. of tokens\n",
    "        for batch in data_iter:\n",
    "            optimizer.zero_grad()\n",
    "            X, X_valid_len, Y, Y_valid_len = [x.to(device) for x in batch]\n",
    "            bos = torch.tensor([tgt_vocab['<bos>']] * Y.shape[0],\n",
    "                               device=device).reshape(-1, 1)\n",
    "            dec_input = d2l.concat([bos, Y[:, :-1]], 1)  # Teacher forcing\n",
    "            Y_hat, _ = net(X, dec_input, X_valid_len)\n",
    "            l = loss(Y_hat, Y, Y_valid_len)\n",
    "            l.sum().backward()  # Make the loss scalar for `backward`\n",
    "            d2l.grad_clipping(net, 1)\n",
    "            num_tokens = Y_valid_len.sum()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                metric.add(l.sum(), num_tokens)\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            animator.add(epoch + 1, (metric[0] / metric[1],))\n",
    "    print(f'loss {metric[0] / metric[1]:.3f}, {metric[1] / timer.stop():.1f} '\n",
    "          f'tokens/sec on {str(device)}')\n",
    "    \n",
    "\n",
    "#@save\n",
    "def predict_seq2seq(net, src_sentence, src_vocab, tgt_vocab, num_steps,\n",
    "                    device, save_attention_weights=False):\n",
    "    \"\"\"Predict for sequence to sequence.\"\"\"\n",
    "    # Set `net` to eval mode for inference\n",
    "    net.eval()\n",
    "    src_tokens = src_vocab[src_sentence.lower().split(' ')] + [\n",
    "        src_vocab['<eos>']]\n",
    "    enc_valid_len = torch.tensor([len(src_tokens)], device=device)\n",
    "    src_tokens = d2l.truncate_pad(src_tokens, num_steps, src_vocab['<pad>'])\n",
    "    # Add the batch axis\n",
    "    enc_X = torch.unsqueeze(\n",
    "        torch.tensor(src_tokens, dtype=torch.long, device=device), dim=0)\n",
    "    enc_outputs = net.encoder(enc_X, enc_valid_len)\n",
    "    dec_state = net.decoder.init_state(enc_outputs, enc_valid_len)\n",
    "    # Add the batch axis\n",
    "    dec_X = torch.unsqueeze(torch.tensor(\n",
    "        [tgt_vocab['<bos>']], dtype=torch.long, device=device), dim=0)\n",
    "    output_seq, attention_weight_seq = [], []\n",
    "    for _ in range(num_steps):\n",
    "        Y, dec_state = net.decoder(dec_X, dec_state)\n",
    "        # We use the token with the highest prediction likelihood as input\n",
    "        # of the decoder at the next time step\n",
    "        dec_X = Y.argmax(dim=2)\n",
    "        pred = dec_X.squeeze(dim=0).type(torch.int32).item()\n",
    "        # Save attention weights (to be covered later)\n",
    "        if save_attention_weights:\n",
    "            attention_weight_seq.append(net.decoder.attention_weights)\n",
    "        # Once the end-of-sequence token is predicted, the generation of the\n",
    "        # output sequence is complete\n",
    "        if pred == tgt_vocab['<eos>']:\n",
    "            break\n",
    "        output_seq.append(pred)\n",
    "    return ' '.join(tgt_vocab.to_tokens(output_seq)), attention_weight_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d983ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tab tensorflow\n",
    "#@save\n",
    "def sequence_mask(X, valid_len, value=0):\n",
    "    \"\"\"Mask irrelevant entries in sequences.\"\"\"\n",
    "    maxlen = X.shape[1]\n",
    "    mask = tf.range(start=0, limit=maxlen, dtype=tf.float32)[\n",
    "        None, :] < tf.cast(valid_len[:, None], dtype=tf.float32)\n",
    "    \n",
    "    if len(X.shape) == 3:\n",
    "        return tf.where(tf.expand_dims(mask, axis=-1), X, value)\n",
    "    else:\n",
    "        return tf.where(mask, X, value)\n",
    "\n",
    "    \n",
    "#@save\n",
    "class MaskedSoftmaxCELoss(tf.keras.losses.Loss):\n",
    "    \"\"\"The softmax cross-entropy loss with masks.\"\"\"\n",
    "    def __init__(self, valid_len):\n",
    "        super().__init__(reduction='none')\n",
    "        self.valid_len = valid_len\n",
    "    \n",
    "    # `pred` shape: (`batch_size`, `num_steps`, `vocab_size`)\n",
    "    # `label` shape: (`batch_size`, `num_steps`)\n",
    "    # `valid_len` shape: (`batch_size`,)\n",
    "    def call(self, label, pred):\n",
    "        weights = tf.ones_like(label, dtype=tf.float32)\n",
    "        weights = sequence_mask(weights, self.valid_len)\n",
    "        label_one_hot = tf.one_hot(label, depth=pred.shape[-1])\n",
    "        unweighted_loss = tf.keras.losses.CategoricalCrossentropy(\n",
    "            from_logits=True, reduction='none')(label_one_hot, pred)\n",
    "        weighted_loss = tf.reduce_mean((unweighted_loss*weights), axis=1)\n",
    "        return weighted_loss\n",
    "    \n",
    "#@save\n",
    "def train_seq2seq(net, data_iter, lr, num_epochs, tgt_vocab, device):\n",
    "    \"\"\"Train a model for sequence to sequence.\"\"\"\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    animator = d2l.Animator(xlabel=\"epoch\", ylabel=\"loss\",\n",
    "                            xlim=[10, num_epochs])\n",
    "    for epoch in range(num_epochs):\n",
    "        timer = d2l.Timer()\n",
    "        metric = d2l.Accumulator(2)  # Sum of training loss, no. of tokens\n",
    "        for batch in data_iter:\n",
    "            X, X_valid_len, Y, Y_valid_len = [x for x in batch]\n",
    "            bos = tf.reshape(tf.constant([tgt_vocab['<bos>']] * Y.shape[0]),\n",
    "                             shape=(-1, 1))\n",
    "            dec_input = tf.concat([bos, Y[:, :-1]], 1)  # Teacher forcing\n",
    "            with tf.GradientTape() as tape:\n",
    "                Y_hat, _ = net(X, dec_input, X_valid_len, training=True)\n",
    "                l = MaskedSoftmaxCELoss(Y_valid_len)(Y, Y_hat)\n",
    "            gradients = tape.gradient(l, net.trainable_variables)\n",
    "            gradients = d2l.grad_clipping(gradients, 1)\n",
    "            optimizer.apply_gradients(zip(gradients, net.trainable_variables))\n",
    "            num_tokens = tf.reduce_sum(Y_valid_len).numpy()\n",
    "            metric.add(tf.reduce_sum(l), num_tokens)\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            animator.add(epoch + 1, (metric[0] / metric[1],))\n",
    "    print(f'loss {metric[0] / metric[1]:.3f}, {metric[1] / timer.stop():.1f} '\n",
    "          f'tokens/sec on {str(device._device_name)}')\n",
    "    \n",
    "#@save\n",
    "def predict_seq2seq(net, src_sentence, src_vocab, tgt_vocab, num_steps,\n",
    "                    save_attention_weights=False):\n",
    "    \"\"\"Predict for sequence to sequence.\"\"\"\n",
    "    src_tokens = src_vocab[src_sentence.lower().split(' ')] + [\n",
    "        src_vocab['<eos>']]\n",
    "    enc_valid_len = tf.constant([len(src_tokens)])\n",
    "    src_tokens = d2l.truncate_pad(src_tokens, num_steps, src_vocab['<pad>'])\n",
    "    # Add the batch axis\n",
    "    enc_X = tf.expand_dims(src_tokens, axis=0)\n",
    "    enc_outputs = net.encoder(enc_X, enc_valid_len, training=False)\n",
    "    dec_state = net.decoder.init_state(enc_outputs, enc_valid_len)\n",
    "    # Add the batch axis\n",
    "    dec_X = tf.expand_dims(tf.constant([tgt_vocab['<bos>']]), axis=0)\n",
    "    output_seq, attention_weight_seq = [], []\n",
    "    for _ in range(num_steps):\n",
    "        Y, dec_state = net.decoder(dec_X, dec_state, training=False)\n",
    "        # We use the token with the highest prediction likelihood as input\n",
    "        # of the decoder at the next time step\n",
    "        dec_X = tf.argmax(Y, axis=2)\n",
    "        pred = tf.squeeze(dec_X, axis=0)\n",
    "        # Save attention weights\n",
    "        if save_attention_weights:\n",
    "            attention_weight_seq.append(net.decoder.attention_weights)\n",
    "        # Once the end-of-sequence token is predicted, the generation of the\n",
    "        # output sequence is complete\n",
    "        if pred == tgt_vocab['<eos>']:\n",
    "            break\n",
    "        output_seq.append(pred.numpy())\n",
    "    return ' '.join(tgt_vocab.to_tokens(tf.reshape(output_seq, shape = -1).numpy().tolist())), attention_weight_seq"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
